# DLNLP_assignment_24-23073916
# Description
In the provided main.py file, the code loads the first 2000 training samples as the training set, the last 2000 training samples as the evaluation set, and the first 500 test samples as the test set. In the report, I also attempted fine-tuning with the first 800 samples.

After the training and test data are transformed into prompts, they are fed into the next step of model loading. Once the model loading is completed, the predict() function generates translation results for the phi-3 model on the test set before fine-tuning. The commented-out section generates results on the training set. After saving the generated results, the model starts fine-tuning and stores the fine-tuned model as a pretrained model. "trained-model" is the model trained with poor prompts, "trained-model2" is the model fine-tuned with 800 samples, and "trained-model3" is the model trained with 2000 samples. Due to GitHub's restrictions on uploading large files, these pretrained models are not provided.

After fine-tuning the model, the code initializes fine_model by loading the pretrained model just saved. fine_model is then used to generate translated text on the test set. Similarly, the code for generating text on the training set is commented out.

The evaluation code of the model is executed by calling the .csv file. The previous steps will save the corresponding .csv files. Since only the testing set generation of the model fine-tuned with 2000 samples and the original model are performed in main(), the data for other scenarios has been uploaded for convenience. Below is a description of each file's content:


origin_test.csv：generated texts of phi-3 model on test dataset

origin_train.csv: generated texts of phi-3 model on train dataset

800_testmodel.csv: generated texts of phi-3 model(tuned with 800 train data) on test dataset

800_trainmodel.csv: generated texts of phi-3 model(tuned with 800 train data) on train dataset

2000_testmodel.csv: generated texts of phi-3 model(tuned with 2000 train data) on test dataset

2000_model.csv: generated texts of phi-3 model(tuned with 2000 train data) on train dataset


After reading the saved generated data, the code will calculate scores, and a dataframe with scores for each line is generated and stored. A new dataframe is created to calculate the average score for each column and output it. In the code, only the calculation of text scores generated by the phi-3 model on the test dataset is performed to expedite the process. The calculation of scores for other texts is not computed, and the code is provided in comments. The calculation of average scores for other texts utilizes pre-saved and uploaded .csv files. Below is a description of each file:


origin_ontest.csv：original phi-3 model scores on test dataset

origin_ontrain.csv：original phi-3 model scores on train dataset

800_ontest.csv：phi-3 tuned with 800 data model scores on test dataset

800_ontrain.csv：phi-3 tuned with 800 data model scores on train dataset

2000_ontest.csv：phi-3 tuned with 2000 data model scores on test dataset

2000_ontrain.csv：phi-3 tuned with 2000 data model scores on train dataset

800_change_prompt_train.csv：phi-3 tuned with 800 data using bad prompt model scores on test dataset 

800_prompt_test.csv：phi-3 tuned with 800 data using bad prompt model scores on train dataset


The score calculation for the model fine-tuned with poor prompts is also provided in comments.

At the end of the code, distribution plots of the BLEURT score and BERT score for the phi-3 model, phi-3 fine-tuned with 800 training data model, and phi-3 fine-tuned with 2000 training data model on both the test set and the training set are drawn. The plots also utilize .csv files, and the plots will be saved in the task folder.

# pakages needed
These are the packages needed for the code:
bitsandbytes
peft
trl
datasets
bleurt
bert_score
flash-attn

In addition, the code will use bluert checkpoints to calculate scores, as the file is too large to be uploaded, you need to download the BLEURT-20 from:https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip

This zip file should be needs to be extracted and the BLEURT-20 folder should be put under task folder.



